Lab Assignment 1

In this assignment, you're going to experiment with a real life armadillo sculpture scanned using a Cyberware 3030 MS 3D scanner at Stanford University. The sculpture is available as part of their 3D Scanning Repository, and is a very dense 3D mesh consisting of 172974 vertices! The mesh is available for you, located at /Module4/Datasets/stanford_armadillo.ply in the course github repository. It is not a Python script file, so don't attempt to load it with a text editor!
![](https://prod-edxapp.edx-cdn.org/assets/courseware/v1/f83af0bb88f3f2b258d91f9575c1cc07/asset-v1:Microsoft+DAT210x+1T2018a+type@asset+block/M5L3-Armadillo.png)


Start up Jupyter and open up the Module4/Module4 - Lab1.ipynb starter code in your browser, then read through it carefully. You will notice the use of a new library, Plyfile. This library loads up the 3D binary mesh for you. The mesh is further converted into a Pandas dataframe for your ease of manipulation.

Before changing any of the code, go ahead and just run through the notebook. You should see the 3D armadillo being rendered. It might take a while, considering its resolution. Your goal is to reduce its dimensionality from three to two using PCA to cast a shadow of the data onto its two most significant principal components. Then render the resulting 2D scatter plot. All of the detailed steps needed to accomplish this are listed inside of the notebook.

------------------------------

Lab Assignment 2

In Lab Assignment 1, you applied PCA to a dataset generated by 3D-scanning an actual sculpture. Real life 3D objects are a good segue to PCA, since it's fun to see its effects on a dataset we can visualize and touch. Another benefit is that all three spatial dimensions, x, y, and z, each measure the same unit-type relative (length), so no extra consideration need be made to account for PCA's weakness of requiring feature scaling.

But now the fun is over. Gaining some practical experience with real-world datasets, which rarely allot you the luxury of having features all of the same scale, will help you see how critical feature scaling is to PCA. In this lab, you're going to experiment with a subset of UCI's Chronic Kidney Disease data set, a collection of samples taken from patients in India over a two month period, some of whom were in the early stages of the disease. There is some starter code for you available in /Module4/Module4 - Lab2.ipynb.

Start the lab by looking through the attribute information on the dataset website. Whenever you are given a dataset, the first thing you should do is find out as much about it as possible, both by reading up on any metadata, as well as by prodding through the actual data. Particularly, pay attention to what the docs say about these three variables: bgr, rc, and wc.

After that, go ahead and load up the kidney_disease.csv dataset from the /Module4/Datasets/ directory. Follow the rest of the steps and reading in the notebook to complete the assignment. Pay special attention to the dataframe's dtypes as assigned by Pandas. You may have to coerce a column into a different data type, if necessary. The last thing you'll do is reduce your dataset down to two principal components by running it through PCA, and then visualizing the resulting output.

---------------------------

Lab Assignment 3

You're not quite done with chronic kidney disease yet—we still need to beat it! In the previous lab assignment, you focused only on three features out of the entire dataset: bgr, rc, and wc. That should have seemed strange to you. How did we know to direct your attention only to those features? The answer, of course, is through PCA. By running PCA on the raw dataset data, we were able to find suitable candidate features to show the importance of feature scaling. For this lab, there will be no starter code. Copy your finished Lab 2, Module4 - Lab2.ipynb file over as Module4 - Lab3.ipynb and start working from that.

Head back over to the dataset page (or you can look at the kidney_disease.names file in your /Module4/Datasets/ directory). Each column has a type listed, e.g. numeric, nominal, etc. We've included a formatted list of the nominal features below. Instead of using an indexer to select just the bgr, rc, and wc, alter your assignment code to drop all the nominal features, which we've listed below for your copy and pasting pleasure. Be sure you select the right axis for columns and not rows, otherwise Pandas will complain! ['id', 'classification', 'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']
Print out your dataset's dtypes, inspect the results. Does everything look like it should / properly numeric encoded? If not, make code changes to coerce the remaining column(s).
Run your assignment and then answer the questions below.

------------------------------

Lab Assignment 4

After having a brief conversation with Joshua Tenenbaum, the primary creator of the isometric feature mapping algorithm, it only seems right that we make your first lab assignment be replicating his canonical, dimensionality reduction research experiment for visual perception! In fact, you will also be using his original dataset (cached website) from December 2000. It consists of 698 samples of 4096-dimensional vectors. These vectors are the coded brightness values of 64x64-pixel heads that have been rendered facing various directions and lighted from many angles. Replicate Dr. Tenenbaum's experiment by:

- Applying both PCA and Isomap to the 698 raw images to derive 2D principal components and a 2D embedding of the data's intrinsic geometric structure.
- Project both onto a 2D scatter plot, with a few superimposed face images on the associated samples.
- Extra: If you're feeling fancy, increase n_components to three, and plot your scatter plot on a 3D chart.

-------------------------------

Lab Assignment 5

Now that you've had your first taste of isomap, let's take your knowledge of it to the next level.

Whatever your high-dimensional samples are, be they images, sound files, or thoughtfully collected attributes, they can all be considered single points in a high dimensional feature-space. Each one of your observations is just a single point. Even with a high dimensionality, it's possible that most or all your samples actually lie on a lower dimension surface. Isomap aims to capture that embedding, which is essentially the motion in the underlying, non-linear degrees of freedom.

By testing isomap on a carefully constructed dataset, you will be able to visually confirm its effectiveness, and gain a deeper understanding of how and why each parameter acts the way it does. The ALOI, Amsterdam Library of Object Images, hosts a huge collection of 1000 small objects that were photographed in such a controlled environment, by systematically varying the viewing angle, illumination angle, and illumination color for each object separately. To really drive home how well isomap does what it claims, this lab will make use of two image sets taken from the ALOI's collection.
![](http://i.imgur.com/So3NlRz.png) ![](http://i.imgur.com/So3NlRz.png)


Manifold extraction, and isomap specifically are really good with vision recognition problems, speech problems, and many other real-world tasks, such as identifying similar objects, or objects that have undergone some change. In the case of the 3D rotating object such as the office chair example from earlier, if every pixel is a feature, at the end of the day, the manifold surface is parametrizable by just the angle of the chair—a single feature!

- Start by having a look through the Module4/Datasets/ALOI/ directory. There are two directories filled with 192 x 144 pixel images. Identify their ordering and try to figure out what's changing between the images. They might not be perfectly ordered, but that doesn't matter to isomap.

- Create a regular Python list object. Then, write a for-loop that iterates over the images in the Module4/Datasets/ALOI/32/ folder, appending each of them to your list. Each .PNG image should first be loaded into a temporary NDArray, just as shown in the Feature Representation reading. Optional: Resample your images down by a factor of two if you have a slower computer. You can also convert the image from  0-255  to  0.0-1.0  if you'd like, but that will have no effect on the algorithm's results.

- Convert the list to a dataframe and run isomap on it to compute the lower dimensional embedding. Be sure to set n_components to 3 so you can visualize your manifold. You can also set the neighborhood size to six.

- Plot the first two manifold components using a 2D scatter plot, then plot the first three components using a 3D scatter plot. Run your assignment and then answer the questions below.
